x-healthcheck: &healthcheck_defaults
  interval: 10s
  timeout: 10s
  retries: 30
  start_period: 10s

services:
  smtp:
    image: tianon/exim4
    hostname: socheat.net
    volumes:
      - "smtp:/var/spool/exim4"
      - "smtp-log:/var/log/exim4"
    networks:
      - sentry

  memcached:
    image: memcached:1.6.21-alpine
    command: ["-I", "${SENTRY_MAX_EXTERNAL_SOURCEMAP_SIZE:-1M}"]
    healthcheck:
      <<: *healthcheck_defaults
      # From: https://stackoverflow.com/a/31877626/5155484
      test: echo stats | nc 127.0.0.1 11211
    networks:
      - sentry

  redis:
    image: redis:6.2.13-alpine
    healthcheck:
      test: redis-cli ping
    volumes:
      - "redis:/data"
    ulimits:
      nofile:
        soft: 10032
        hard: 10032
    networks:
      - sentry

  postgres:
    # Using the same postgres version as Sentry dev for consistency purposes
    image: "postgres:14.5"
    networks:
      - sentry
    command:
      [
        "postgres",
        "-c",
        "wal_level=logical",
        "-c",
        "max_replication_slots=1",
        "-c",
        "max_wal_senders=1",
      ]
    environment:
      POSTGRES_HOST_AUTH_METHOD: "trust"
    entrypoint: /opt/sentry/postgres-entrypoint.sh
    configs:
      - source: postgres-entrypoint.sh
        target: /opt/sentry/postgres-entrypoint.sh
        mode: 0755
      - source: postgres-init_hba.sh
        target: /opt/sentry/init_hba.sh
        mode: 0755
      - source: postgres-wal2json.so
        target: /opt/sentry/wal2json/wal2json.so
    volumes:
      - "postgres:/var/lib/postgresql/data"

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    environment:
      # https://docs.confluent.io/platform/current/installation/docker/config-reference.html#cp-kakfa-example
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@127.0.0.1:29093"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_NODE_ID: "1"
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:29092,INTERNAL://0.0.0.0:9093,EXTERNAL://0.0.0.0:9092,CONTROLLER://0.0.0.0:29093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://127.0.0.1:29092,INTERNAL://kafka:9093,EXTERNAL://kafka:9092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
      KAFKA_OFFSETS_TOPIC_NUM_PARTITIONS: "1"
      KAFKA_LOG_RETENTION_HOURS: "24"
      KAFKA_MESSAGE_MAX_BYTES: "50000000" #50MB or bust
      KAFKA_MAX_REQUEST_SIZE: "50000000" #50MB on requests apparently too
      CONFLUENT_SUPPORT_METRICS_ENABLE: "false"
      KAFKA_LOG4J_LOGGERS: "kafka.cluster=WARN,kafka.controller=WARN,kafka.coordinator=WARN,kafka.log=WARN,kafka.server=WARN,state.change.logger=WARN"
      KAFKA_LOG4J_ROOT_LOGLEVEL: "WARN"
      KAFKA_TOOLS_LOG4J_LOGLEVEL: "WARN"
    ulimits:
      nofile:
        soft: 4096
        hard: 4096
    networks:
      - sentry
    volumes:
      - "kafka:/var/lib/kafka"
      - "kafka-secrets:/etc/kafka/secrets"
    # healthcheck:
    #   test: ["CMD-SHELL", "/usr/bin/kafka-topics --bootstrap-server kafka:9092 --list"]
    #   interval: 10s
    #   timeout: 10s
    #   retries: 30
    #   start_period: 10s

  clickhouse:
    image: yandex/clickhouse-server:20.3.9.70
    networks:
      - sentry
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    configs:
      - source: clickhouse.xml
        target: /etc/clickhouse-server/config.d/sentry.xml
    volumes:
      - "clickhouse:/var/lib/clickhouse"
      - "clickhouse-log:/var/log/clickhouse-server"
    environment:
      # This limits Clickhouse's memory to 30% of the host memory
      # If you have high volume and your search return incomplete results
      # You might want to change this to a higher value (and ensure your host has enough memory)
      MAX_MEMORY_USAGE_RATIO: 0.3
    healthcheck:
      test: [
          "CMD-SHELL",
          # Manually override any http_proxy envvar that might be set, because
          # this wget does not support no_proxy. See:
          # https://github.com/getsentry/self-hosted/issues/1537
          "http_proxy='' wget -nv -t1 --spider 'http://localhost:8123/' || exit 1",
        ]
      interval: 10s
      timeout: 10s
      retries: 30

networks:
  sentry:
    name: sentry
    external: true

configs:
  clickhouse.xml:
    file: services/clickhouse/config.xml
  postgres-entrypoint.sh:
    file: services/postgres/postgres-entrypoint.sh
  postgres-init_hba.sh:
    file: services/postgres/init_hba.sh
  postgres-wal2json.so:
    file: services/postgres/wal2json.so

volumes:
  smtp:
  smtp-log:
  redis:
  postgres:
  kafka:
  kafka-secrets:
  clickhouse:
  clickhouse-log:
